---
title: 关于机器学习在线预测的任务学习笔记
date: 2017-08-25 09:58:47
tags: tensorflow
---

#前言
明星的脸识别是微博的特色，有海量的明星的图片，有巨大的识别需求。明星脸识别有特别的困难，常用人脸识别方案，所用的照片表情，造型比较少，不同人之间相差比较大，而明星脸表情丰富，造型多变，有些整容脸连人脑都分不清，更不说机器识别了。
在者，在网页中的推荐的广告，如果广告能够切中用户的意愿，就不可以不必费尽力气，这种广告效果自然会好的很多。

#应用
 在这里理想态的机器学习平台承担了离线训练和在线预测任务。将实施产生的数据传输到后台，用于提取特征，离线训练，越来越多的业务使用深度学习方法，TensorFlow/Caffe框架被集成进来。
     目前，离线训练主要使用GPU机群，计算机群有一部分属于阿里云。
#TensorFlow提供的分布式的计算模式
Tensorflow分布式计算与HPC的MPI分布计算区别很大，MPI进程相互平等，保证没有瓶颈的进程，MPI_IO也设计每个主机都可以均匀分担IO的压力，MPI进程上计算任务也要求均匀划分，保证每个进程的计算进度保持一致，MPI进程之间也只是只交换数据块的边界，尽量减少网络流量，压缩通信时间。
   TensorFlow的分布式计算设计的简单粗暴。早若干个参数服务器中，和若干个劳工组成一个机群，将每一部运算得到的参数提交给参数服务器，参数服务器将来自所有劳工的参数合并起来，得到全局参数，然后将全局参数，发送给劳工，劳工在全局参数的基础在做下一步的运算，
   TensorFlow采用主从模式，参数服务器是瓶颈。每步都要传递所有的参数，网络流量太大，假设每个劳工上参数占用内存1GB，机群包含1个参数服务器和10个劳工，那么每个迭代步将产生20GB的网络流量，按照10GbE网络计算，通信时间至少需16秒。而实际上，每个batch数据的运算时间可能还不足1秒，模型参数占用的内存可能远大于1GB。从理论分析来看，TensorFlow分布式运算的效率不如MPI。
   有人说深度学习只是高性能计算的一种特殊模式，但其实不这样的，TensorFlow与HPC机群有重大区别。
#TensorFlow与HPC机群的区别
HPC机群有3大特点：高性能计算芯片，高速的计算网络，高速的并行存储，而TensorFlow在其中只有一个高端的GPU。
#案列
劳工在一批数据的上训练的得到△W和△B（合称为△P）称为一步训练，所有的劳工在完成一步训练后，暂停训练，将自己等到的△P发送到参数服务器，参数服务器一直等待，直到来自所有劳工参数变化量△P相加取平均值，然后用这个参数去更新旧的参数，得到新的参数P，借助着P发送给所有劳工，劳工在接收到这个新的参数在做下一步计算。
&nbsp;   与用一台服务器相比，用N台劳工同时训练+同步更新参数等价于将batch的规模扩大了N倍。具体来说，如果用1台服务器时，每步训练采用100张数字图片（batch=100）,那么用4个劳工得到的参数变化量（即∆P）同步更新，就相当于每步训练采用400张数字图片（batch=400）。从而，参数变化得更平稳，收敛更快。
&nbsp;   但同步更新也有缺点：整体速度取决于最慢的那个劳工，如果劳工之间软硬件差别较大，有明显的速度差异，同步更新计算速度较慢。为了避免这种速度差异，TensorFlow提供了异步更新策略。
&nbsp; 当有一个劳工训练得到一个参数变化量∆P时，不妨假设是图中的Device A，该劳工立即将∆P发送给参数服务器。参数服务器接收到来自劳工Device A的∆P后，不等待其它的劳工，立即用∆P更新全局参数，得到全局参数P，紧接着将P发送给劳工Device A。劳工Device A接收到全局参数P后，立即开始下一步训练。在异步更新的参数，它等价于只有一台服务器训练，都是每次只用一小批图像训练，只是各批上场次序，由劳工随机运行状态所决定。

     